{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools as it\n",
    "\n",
    "import helpers_08\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Old NB lab 06 (make VGG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern CNN Architectures\n",
    "\n",
    "## Loading TensorBoard Graphs for pre-built models\n",
    "\n",
    "Inside of the `prebuilt` folder, there are TensorBoard graphs exported for VGGNet, InceptionV1, and ResNet models. You will use these as guidance for creating your own layer functions. Load them up in TensorBoard by using the following command (assuming you're running this command from the `notebooks` directory:\n",
    "\n",
    "```shell\n",
    "tensorboard --logdir=prebuilt\n",
    "```\n",
    "\n",
    "Navigate to `localhost:6006` in your browser. After you click on the \"Graphs\" link, you'll be able to switch to the various reference graphs by choosing from the dropdown \"runs\" option.\n",
    "\n",
    "![](images/tb1.png)\n",
    "\n",
    "![](images/tb2.png)\n",
    "\n",
    "Below is a description of each graph:\n",
    "\n",
    "* **vgg_19**: The entire VGGNet network (19-layer version)\n",
    "\n",
    "The goal of this notebook/lab is to recreate VGG in TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Layer functions\n",
    "\n",
    "#### `conv()`\n",
    "\n",
    "Creates a 2D convolutional layer with Xavier-initialized weights. Automatically detects depth from previous layer\n",
    "\n",
    "* **Arguments**\n",
    "    * `inputs`: 4D `Tensor` with shape `[batch_size, height, width, channels]`\n",
    "    * `depth`: The number of output channels this convolution should create. Scalar number.\n",
    "    * `ksize`: 2D list of integers. The dimensions of convolutional kernel (ie. [3,3], [5,5], etc)\n",
    "    * `strides`: 2D list of integers. The strides of the convolution (defaults to `[1, 1]`)\n",
    "    * `padding`: String, accepted values `'SAME'` or `'VALID'`. The type of padding to use. Defaults to `SAME`.\n",
    "    * `bval`: Floating point number. The initial values for biases\n",
    "    * `activation_fn`: Lambda function. The activation function to use. defaults to `tf.nn.relu`\n",
    "    * `scope`: The name to use for the variable scope.\n",
    "    \n",
    "* **Returns**\n",
    "    * A 4D `Tensor` after the convolution operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(inputs, depth, ksize, strides=[1, 1], padding='SAME',\n",
    "         bval=0.01, activation_fn=tf.nn.relu, scope=None):\n",
    "    prev_shape = inputs.get_shape().as_list()\n",
    "    prev_depth = prev_shape[-1]\n",
    "    kshape = ksize + [prev_depth, depth]\n",
    "    strides = [1] + strides + [1]\n",
    "    fan_in = np.prod(prev_shape[1:], dtype=np.float32)\n",
    "    with tf.variable_scope(scope, 'conv_layer'):\n",
    "        xavier_stddev = tf.sqrt(tf.constant(2.0, dtype=tf.float32) / fan_in, name='xavier_stddev')\n",
    "        w = tf.Variable(tf.truncated_normal(kshape, stddev=xavier_stddev), name='kernel')\n",
    "        b = tf.Variable(tf.constant(bval, shape=[depth]), name='bias')\n",
    "        conv = tf.nn.conv2d(inputs, w, strides, padding, name='conv')\n",
    "        z = tf.nn.bias_add(conv, b)\n",
    "        return z if activation_fn is None else activation_fn(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fully_connected()`\n",
    "\n",
    "Creates a 2D fully connected layer with Xavier-initialized weights. Automatically detects depth from previous layer.\n",
    "\n",
    "* **Arguments**\n",
    "    * `inputs`: 2D `Tensor` with shape `[batch_size, depth]`\n",
    "    * `depth`: Scalar. The number of neurons in this layer\n",
    "    * `bval`: Floating point number. The initial values for biases\n",
    "    * `activation_fn`: Lambda function. The activation function to use. defaults to `tf.nn.relu`\n",
    "    * `keep_prob`: Scalar float indicating the keep probability for dropout (if any)\n",
    "    * `scope`: The name to use for the variable scope.\n",
    "    \n",
    "* **Returns**\n",
    "    * A 2D `Tensor` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(inputs, depth, bval=0.01, activation_fn=tf.nn.relu, \n",
    "                          keep_prob=None, scope=None):\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    prev_shape = inputs.get_shape().as_list()\n",
    "    fan_in = prev_shape[-1]\n",
    "    with tf.variable_scope(scope, 'fully_connected'):\n",
    "        xavier_stddev = tf.sqrt(tf.constant(2.0, dtype=tf.float32) / fan_in, name='xavier_stddev')\n",
    "        w = tf.Variable(tf.truncated_normal([fan_in, depth], stddev=xavier_stddev), name='W')\n",
    "        b = tf.Variable(tf.constant(bval, shape=[depth]), name='bias')\n",
    "        z = tf.matmul(inputs, w) + b\n",
    "        a = z if activation_fn is None else activation_fn(z)\n",
    "        return a if keep_prob is None else tf.nn.dropout(a, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `avgpool()` and `maxpool()`\n",
    "\n",
    "Performs average pooling and max pooling, respectively\n",
    "\n",
    "* **Arguments**\n",
    "    * `inputs`: 4D `Tensor` with shape `[batch_size, height, width, channels]`\n",
    "    * `ksize`: 2D list of integers. The dimensions of pooling kernel (ie. [2,2] etc)\n",
    "    * `strides`: 2D list of integers. The strides of the pooling kernel.\n",
    "    * `padding`: String, accepted values `'SAME'` or `'VALID'`. The type of padding to use. Defaults to `VALID`.\n",
    "    * `name`: The name to use for the variable scope.\n",
    "    \n",
    "* **Returns**\n",
    "    * A 4D `Tensor` after the pooling operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avgpool(inputs, ksize, strides, padding='VALID', name=None):\n",
    "    with tf.name_scope(name, 'avgpool'):\n",
    "        ksize = [1] + ksize + [1]\n",
    "        strides = [1] + strides + [1]\n",
    "        return tf.nn.avg_pool(inputs, ksize, strides, padding)\n",
    "\n",
    "    \n",
    "def maxpool(inputs, ksize, strides, padding='VALID', name=None):\n",
    "    with tf.name_scope(name, 'maxpool'):\n",
    "        ksize = [1] + ksize + [1]\n",
    "        strides = [1] + strides + [1]\n",
    "        return tf.nn.max_pool(inputs, ksize, strides, padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `flatten()`\n",
    "\n",
    "Flattens an N dimensional `Tensor` into a 2D `Tensor` (ie from shape `[batch_size, a, b, c]` to shape `[batch_size, a*b*c]`\n",
    "\n",
    "* **Arguments**\n",
    "    * `inputs`: The input `Tensor` to flatten\n",
    "    * `scope`: The name to use for the variable scope.\n",
    "    \n",
    "* **Returns**\n",
    "    * A 2D flattened `Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(inputs, name=None):\n",
    "    prev_shape = inputs.get_shape().as_list()\n",
    "    fan_in = np.prod(prev_shape[1:])\n",
    "    with tf.name_scope(name, 'flatten'):\n",
    "        return tf.reshape(inputs, [-1, fan_in])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGNet\n",
    "\n",
    "[VGGNet paper on arXiv.org](https://arxiv.org/abs/1409.1556)\n",
    "\n",
    "![](images/vggtable.png)\n",
    "\n",
    "Use the above layer functions to recreate the 19 layer VGGNet from the above table (column E). Your model function should expect two parameter inputs:\n",
    "\n",
    "* `inputs`: a 4D tensor with dtype `float32` and shape `[batch_size, 224, 224, 3]`\n",
    "* `keep_prob`: A scalar `Tensor` with dtype `float32` representing the keep_probability for dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vggnet(inputs, keep_prob):\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "    ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test module: Run once you're ready to check your work\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    inputs = tf.random_normal([10, 224, 224, 3])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    output = vggnet(inputs, keep_prob)\n",
    "    writer = tf.summary.FileWriter('tbout/vggnet', graph=graph)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Scope [from old NB 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.variable_scope()`\n",
    "\n",
    "Throughout the class, we've created our variables directly, using `tf.Variable()`. This is the simplest way to use Variables, as it doesn't involve any programming \"magic\". However, TensorFlow includes another way to create Variables so that it is easier to access previously created Variables. It also forces you to be more precise with how you use Variables, and allows you to assign \"presets\" for various parameters in your Variables, such as the initialization values.\n",
    "\n",
    "Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_graph = tf.Graph()\n",
    "with var_graph.as_default():\n",
    "    with tf.variable_scope('my_var_scope') as scope:\n",
    "        w_init = tf.truncated_normal_initializer()\n",
    "        b_init = tf.zeros_initializer()\n",
    "        w = tf.get_variable('w', shape=[10, 10], initializer=w_init)\n",
    "        b = tf.get_variable('b', shape=[10], initializer=b_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates two variables, `w` and `b`, using the [`tf.get_variable()`](https://www.tensorflow.org/api_docs/python/tf/get_variable) method. The primary parameter is the string `name` of the `Variable` you'd like to retrieve. If a `Variable` in the scope already has that name, it will retrieve that `Variable` object. Otherwise, it will create that `Variable`. Because neither `w` nor `b` were created before, it creates them from scratch.\n",
    "\n",
    "### Reusing variables\n",
    "\n",
    "Now if we want to reuse them at a later time, we can access them by calling the `variable_scope` again, and setting its `reuse` parameter to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with var_graph.as_default():\n",
    "    with tf.variable_scope('my_var_scope', reuse=True) as scope:\n",
    "        w_again = tf.get_variable('w')\n",
    "        b_again = tf.get_variable('b')\n",
    "        assert w == w_again\n",
    "        assert b == b_again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we _must_ set `reuse` to `True`. If we don't, TensorFlow will complain at us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable my_var_scope/w already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n",
      "\n",
      "  File \"<ipython-input-67-fb67dcccc716>\", line 6, in <module>\n",
      "    w = tf.get_variable('w', shape=[10, 10], initializer=w_init)\n",
      "  File \"/Users/Sam/anaconda/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/Users/Sam/anaconda/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with var_graph.as_default():\n",
    "    with tf.variable_scope('my_var_scope') as scope:\n",
    "        try:\n",
    "            w_again = tf.get_variable('w')\n",
    "            b_again = tf.get_variable('b')\n",
    "        except ValueError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative to passing `reuse` into the `variable_scope` parameter, we can set it after the fact by using the `variable_scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with var_graph.as_default():\n",
    "    with tf.variable_scope('my_var_scope') as scope:\n",
    "        scope.reuse_variables()\n",
    "        w_again = tf.get_variable('w')\n",
    "        b_again = tf.get_variable('b')\n",
    "        assert w == w_again\n",
    "        assert b == b_again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the current variable scope with `tf.get_variable_scope()`; similar to `tf.get_default_graph()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with var_graph.as_default():\n",
    "    with tf.variable_scope('my_var_scope'):\n",
    "        scope = tf.get_variable_scope()\n",
    "        scope.reuse_variables()\n",
    "        w_again = tf.get_variable('w')\n",
    "        b_again = tf.get_variable('b')\n",
    "        assert w == w_again\n",
    "        assert b == b_again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable initializers\n",
    "\n",
    "Notice that we used two Operations we've never seen before: `truncated_normal_initializer` and `zeros_initializer`. They are similar to what we've used in the past to initialize Variables: `truncated_normal` and `zeros`. The `initializer` Operations are designed to be used with `tf.get_variable()`- they define a way to create an arbitrary initial value inside a Tensor, regardless of shape.\n",
    "\n",
    "Notice how we don't specify the shape of the `Variable` until we call `tf.get_variable()`. This separation allows us to reuse the same initialization `Operation` for multiple Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_graph = tf.Graph()\n",
    "with init_graph.as_default():\n",
    "    with tf.variable_scope('my_var_scope') as scope:\n",
    "        w_init = tf.truncated_normal_initializer()\n",
    "        w1 = tf.get_variable('w1', shape=[10, 10], initializer=w_init)\n",
    "        w2 = tf.get_variable('w2', shape=[200], initializer=w_init)\n",
    "        w3 = tf.get_variable('w3', shape=[300,10,10], initializer=w_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting default parameters\n",
    "\n",
    "Above, we use the line `initializer=w_init` over and over again. It would be nice if we could have that automatically be done for us. Luckily, we can! The `variable_scope()` function includes several options that we can provide as a default for any `Variables` we create inside that scope. To set `w_init` as our default initializer, we simple pass in `initializer=w_init` inside of the call to `variable_scope`. Then, we can leave the `initializer=` portion out of `get_variable()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_init_graph = tf.Graph()\n",
    "with default_init_graph.as_default():\n",
    "    w_init = tf.truncated_normal_initializer()\n",
    "    with tf.variable_scope('my_var_scope', initializer=w_init) as scope:\n",
    "        w1 = tf.get_variable('w1', shape=[10, 10])\n",
    "        w2 = tf.get_variable('w2', shape=[200])\n",
    "        w3 = tf.get_variable('w3', shape=[300,10,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These default parameters can be nested, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nested_init_graph = tf.Graph()\n",
    "with nested_init_graph.as_default():\n",
    "    init1 = tf.truncated_normal_initializer()\n",
    "    init2 = tf.zeros_initializer()\n",
    "    with tf.variable_scope('var_scope_1', initializer=init1) as scope:\n",
    "        w1 = tf.get_variable('w1', shape=[10, 10])\n",
    "        with tf.variable_scope('var_scope_2', initializer=init2):\n",
    "            w2 = tf.get_variable('w2', shape=[200])\n",
    "            w3 = tf.get_variable('w3', shape=[300,10,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG, Devices, etc. [from old NB 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import collections\n",
    "import os.path\n",
    "import re\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from lxml import etree\n",
    "\n",
    "import helpers\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecords\n",
    "\n",
    "The below code downloads the Tiny ImageNet dataset, which is a miniaturized and simplified version of the ILSVRC dataset. There are only 200 classes as opposed to 1000, and each of the files has been scaled to 64x64 pixels. We're mainly using it due to the fact that it is a smaller dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
    "helpers.mkdir('data')\n",
    "helpers.mkdir(os.path.join('data', '12'))\n",
    "zip_path = helpers.download(url, os.path.join('data', '12', 'tinyimagenet.zip'))\n",
    "zipped = zipfile.ZipFile(zip_path, 'r')\n",
    "data_path = os.path.join('data', '12', 'tinyimagenet')\n",
    "zipped.extractall(data_path)\n",
    "zipped.close()\n",
    "os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create helper structures for converting from an integer id to a string synset label (and back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_synset = []\n",
    "with open(os.path.join(data_path, 'tiny-imagenet-200', 'wnids.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        id_to_synset.append(line.strip())\n",
    "synset_to_id = {\n",
    "    synset: i for i, synset in enumerate(id_to_synset)\n",
    "}\n",
    "# Check that ids were assigned correctly\n",
    "assert all(\n",
    "    synset_to_id[id_to_synset[i]] == i for i in range(len(id_to_synset))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Common helper function pattern for creating Feature protos\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_path = os.path.join('data', '12', 'tinyimagenet_train.tfrecords')\n",
    "writer = tf.python_io.TFRecordWriter(tfrecord_path)\n",
    "for root, dirs, files in os.walk(os.path.join(data_path, 'tiny-imagenet-200', 'train')):\n",
    "    for file in files:\n",
    "        if file.endswith('.JPEG'):\n",
    "            synset = file[:9]\n",
    "            label = synset_to_id[synset]\n",
    "            with open(os.path.join(root, file), 'rb') as f:\n",
    "                image_bytes = f.read()\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image_bytes': _bytes_feature(image_bytes),\n",
    "                'label': _int64_feature(label)\n",
    "            }))\n",
    "            writer.write(example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_to_label = {}\n",
    "with open(os.path.join(data_path, 'tiny-imagenet-200', 'val', 'val_annotations.txt')) as f:\n",
    "    for line in f:\n",
    "        info = line.split()\n",
    "        filename = info[0]\n",
    "        synset = info[1]\n",
    "        label = synset_to_id[synset]\n",
    "        name_to_label[filename] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation data\n",
    "val_path = os.path.join('data', '12', 'tinyimagenet_val.tfrecords')\n",
    "writer = tf.python_io.TFRecordWriter(tfrecord_path)\n",
    "for root, dirs, files in os.walk(os.path.join(data_path, 'tiny-imagenet-200', 'val')):\n",
    "    for file in files:\n",
    "        if file.endswith('.JPEG'):\n",
    "            label = name_to_label[file]\n",
    "            with open(os.path.join(root, file), 'rb') as f:\n",
    "                image_bytes = f.read()\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image_bytes': _bytes_feature(image_bytes),\n",
    "                'label': _int64_feature(label)\n",
    "            }))\n",
    "            writer.write(example.SerializeToString())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queues\n",
    "\n",
    "Using Queues will help us ensure that we're consistently filling the GPU ram on our system. They asynchronously pull in and preprocess data before putting them into queues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Should increase these for GPU systems\n",
    "BATCH_SIZE = 5\n",
    "NUM_THREADS = 2\n",
    "CAPACITY = 100 + 3 * BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_label_queue():\n",
    "    with tf.name_scope('input_queue'):\n",
    "        # Step 1: create the list of filenames\n",
    "        # TensorFlow has a helper for this: tf.train.match_filenames_once()\n",
    "        # https://www.tensorflow.org/api_docs/python/tf/train/match_filenames_once\n",
    "        train_path = os.path.join('data', '12', 'tinyimagenet_train.tfrecords')\n",
    "        val_path = os.path.join('data', '12', 'tinyimagenet_val.tfrecords')\n",
    "        filenames = [train_path, val_path]\n",
    "\n",
    "        # Step 2: create a Queue that goes through \n",
    "        filename_queue = tf.train.string_input_producer([train_path])\n",
    "\n",
    "        reader = tf.TFRecordReader()\n",
    "\n",
    "        key, example = reader.read(filename_queue)\n",
    "        features = tf.parse_single_example(\n",
    "            example,\n",
    "            features={\n",
    "                'image_bytes': tf.FixedLenFeature([], tf.string),\n",
    "                'label': tf.FixedLenFeature([], tf.int64)\n",
    "            }\n",
    "        )\n",
    "\n",
    "        image_bytes = features['image_bytes']\n",
    "        label = tf.to_int32(features['label'])\n",
    "\n",
    "        # PREPROCESS BEFORE ADDING TO QUEUE\n",
    "        image = tf.image.decode_jpeg(image_bytes, channels=3)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        image = tf.image.resize_bilinear(image, [224, 224])\n",
    "        image = tf.squeeze(image)\n",
    "        image = tf.to_float(image)\n",
    "        image = (image - 127.5) / 127.5\n",
    "        # \n",
    "\n",
    "        image_batch, label_batch = tf.train.shuffle_batch(\n",
    "            [image, label],\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_threads=NUM_THREADS,\n",
    "            capacity=CAPACITY,\n",
    "            min_after_dequeue=15\n",
    "        )\n",
    "        return image_batch, label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Proto\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/config.proto#L172-L250\n",
    "\n",
    "When creating a `Session`, you can pass in a set of options in the form of a ConfigProto protocol buffer. You simply add the options you want to the `ConfigProto` initialization function. Here are a couple of the things you can do with the config proto:\n",
    "\n",
    "* Quietly place Ops on different devices if you explicitly call `with tf.device()` using a device that doesn't exist\n",
    "* Print where devices are placed as they are created\n",
    "* Tell TensorFlow to automatically use all of GPU memory immediately, but rather allocate it as necessary\n",
    "* Set a timeout for Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu_config = tf.GPUOptions(\n",
    "    allow_growth=True\n",
    ")\n",
    "\n",
    "config=tf.ConfigProto(\n",
    "    allow_soft_placement=True,\n",
    "    log_device_placement=True,\n",
    "    gpu_options=gpu_config\n",
    ")    \n",
    "    \n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi GPU TensorFlow\n",
    "\n",
    "By default in TensorFlow, Operations are automatically placed on a CPU or GPU (if available). In general, an Operation will be automatically placed on a GPU unless there isn't a GPU implementation of that `Operation` (assuming you have TensorFlow installed for GPUs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.random_normal([100, 100])\n",
    "    b = tf.random_normal([100, 100])\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    c = tf.matmul(a, b)\n",
    "    \n",
    "config=tf.ConfigProto(\n",
    "    allow_soft_placement=True,\n",
    "    log_device_placement=True\n",
    ")    \n",
    "    \n",
    "with tf.Session(config=config) as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Adjusting our layer functions\n",
    "\n",
    "In order to properly utilize multiple GPUs, we're going to need to adjust our layer functions to place all Variables on CPU. This will ensure that we have proper sharing of our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(inputs, depth, ksize, strides=[1, 1], padding='SAME',\n",
    "         bval=0.01, activation=tf.nn.relu, scope=None):\n",
    "    with tf.variable_scope(scope, 'conv_layer'):\n",
    "        with tf.device('/cpu:0'):\n",
    "            prev_shape = inputs.get_shape().as_list()\n",
    "            prev_depth = prev_shape[-1]\n",
    "            kshape = ksize + [prev_depth, depth]\n",
    "            strides = [1] + strides + [1]\n",
    "            fan_in = np.prod(prev_shape[1:], dtype=np.float32)\n",
    "            xavier_stddev = tf.sqrt(tf.constant(2.0, dtype=tf.float32) / fan_in, name='xavier_stddev')\n",
    "            w_init = tf.truncated_normal_initializer(stddev=xavier_stddev)\n",
    "            w = tf.get_variable('kernel', shape=kshape, initializer=w_init)\n",
    "            b = tf.get_variable('bias', shape=[depth], initializer=tf.constant_initializer(bval))\n",
    "        conv = tf.nn.conv2d(inputs, w, strides, padding, name='conv')\n",
    "        z = tf.nn.bias_add(conv, b)\n",
    "        return z if activation is None else activation(z)\n",
    "    \n",
    "def fully_connected_layer(inputs, depth, bval=0.01, activation=tf.nn.relu, \n",
    "                          keep_prob=None, scope=None):\n",
    "    with tf.variable_scope(scope, 'fully_connected'):\n",
    "        with tf.device('/cpu:0'):\n",
    "            inputs = tf.convert_to_tensor(inputs)\n",
    "            prev_shape = inputs.get_shape().as_list()\n",
    "            fan_in = prev_shape[-1]\n",
    "            xavier_stddev = tf.sqrt(tf.constant(2.0, dtype=tf.float32) / fan_in, name='xavier_stddev')\n",
    "            w_init = tf.truncated_normal_initializer(stddev=xavier_stddev)\n",
    "            w = tf.get_variable('weight', shape=[fan_in, depth], initializer=w_init)\n",
    "            b = tf.get_variable('bias', shape=[depth], initializer=tf.constant_initializer(bval))\n",
    "        z = tf.matmul(inputs, w) + b\n",
    "        a = z if activation is None else activation(z)\n",
    "        return a if keep_prob is None else tf.nn.dropout(a, keep_prob)\n",
    "\n",
    "def flatten(inputs, name=None):\n",
    "    prev_shape = inputs.get_shape().as_list()\n",
    "    fan_in = np.prod(prev_shape[1:])\n",
    "    with tf.name_scope(name, 'flatten'):\n",
    "        return tf.reshape(inputs, [-1, fan_in])\n",
    "\n",
    "def vgg_model(inputs):\n",
    "    with tf.name_scope('vgg_net'):\n",
    "        conv = conv2d(inputs, 64, [3, 3], activation=tf.nn.relu, scope='c1')\n",
    "        conv = conv2d(conv, 64, [3, 3], activation=tf.nn.relu, scope='c2')\n",
    "        pool = tf.layers.max_pooling2d(conv, [2, 2], [2, 2])\n",
    "        conv = conv2d(pool, 128, [3, 3], activation=tf.nn.relu, scope='c3')\n",
    "        conv = conv2d(conv, 128, [3, 3], activation=tf.nn.relu, scope='c4')\n",
    "        pool = tf.layers.max_pooling2d(conv, [2, 2], [2, 2])\n",
    "        conv = conv2d(pool, 256, [3, 3], activation=tf.nn.relu, scope='c5')\n",
    "        conv = conv2d(conv, 256, [3, 3], activation=tf.nn.relu, scope='c6')\n",
    "        conv = conv2d(conv, 256, [3, 3], activation=tf.nn.relu, scope='c7')\n",
    "        conv = conv2d(conv, 256, [3, 3], activation=tf.nn.relu, scope='c8')\n",
    "        pool = tf.layers.max_pooling2d(conv, [2, 2], [2, 2])\n",
    "        conv = conv2d(pool, 512, [3, 3], activation=tf.nn.relu, scope='c9')\n",
    "        conv = conv2d(conv, 512, [3, 3], activation=tf.nn.relu, scope='c10')\n",
    "        conv = conv2d(conv, 512, [3, 3], activation=tf.nn.relu, scope='c11')\n",
    "        conv = conv2d(conv, 512, [3, 3], activation=tf.nn.relu, scope='c12')\n",
    "        pool = tf.layers.max_pooling2d(conv, [2, 2], [2, 2])\n",
    "        conv = conv2d(pool, 512, [3, 3], activation=tf.nn.relu, scope='c13')\n",
    "        conv = conv2d(conv, 512, [3, 3], activation=tf.nn.relu, scope='c14')\n",
    "        conv = conv2d(conv, 512, [3, 3], activation=tf.nn.relu, scope='c15')\n",
    "        conv = conv2d(conv, 512, [3, 3], activation=tf.nn.relu, scope='c16')\n",
    "        pool = tf.layers.max_pooling2d(conv, [2, 2], [2, 2])\n",
    "        flat = flatten(pool)\n",
    "        fc = fully_connected_layer(flat, 4096, activation=tf.nn.relu, scope='f17')\n",
    "        fc = fully_connected_layer(fc, 4096, activation=tf.nn.relu, scope='f18')\n",
    "        logits = fully_connected_layer(fc, 1000, scope='f19')\n",
    "        return logits\n",
    "\n",
    "def vgg_loss(logits, labels):\n",
    "    with tf.name_scope('loss'):\n",
    "        labels_onehot = tf.one_hot(labels, 1000)\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels_onehot, logits=logits)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L101-L136\n",
    "\"\"\"\n",
    "\n",
    "def average_gradients(tower_grads):\n",
    "    \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "    Note that this function provides a synchronization point across all towers.\n",
    "    Args:\n",
    "    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "      is over individual gradients. The inner list is over the gradient\n",
    "      calculation for each tower.\n",
    "    Returns:\n",
    "     List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "     across all towers.\n",
    "    \"\"\"\n",
    "    with tf.name_scope('merge_losses'):\n",
    "        average_grads = []\n",
    "        for grad_and_vars in zip(*tower_grads):\n",
    "            # Note that each grad_and_vars looks like the following:\n",
    "            #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "            grads = []\n",
    "            for g, _ in grad_and_vars:\n",
    "                # Add 0 dimension to the gradients to represent the tower.\n",
    "                expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "                # Append on a 'tower' dimension which we will average over below.\n",
    "                grads.append(expanded_g)\n",
    "\n",
    "            # Average over the 'tower' dimension.\n",
    "            grad = tf.concat(axis=0, values=grads)\n",
    "            grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "            # Keep in mind that the Variables are redundant because they are shared\n",
    "            # across towers. So .. we will just return the first tower's pointer to\n",
    "            # the Variable.\n",
    "            v = grad_and_vars[0][1]\n",
    "            grad_and_var = (grad, v)\n",
    "            average_grads.append(grad_and_var)\n",
    "        return average_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_GPU = 2\n",
    "DECAY_STEPS = 100000\n",
    "DECAY_FACTOR  = 0.998\n",
    "CKPT_PATH = 'vggnet'\n",
    "multi_graph = tf.Graph()\n",
    "# Note how we're placing everything on the CPU by default\n",
    "with multi_graph.as_default(), tf.device('cpu:0'):\n",
    "    \n",
    "    gs_init = tf.constant_initializer(0)\n",
    "    global_step = tf.get_variable('global_step', [], \n",
    "                                  initializer=gs_init, trainable=False)\n",
    "    inc_step = tf.assign_add(global_step, 1, name='inc_step')\n",
    "    \n",
    "    lr = tf.train.exponential_decay(0.05, \n",
    "                                    global_step,\n",
    "                                    DECAY_STEPS,\n",
    "                                    DECAY_FACTOR,\n",
    "                                    staircase=True)\n",
    "    \n",
    "    opt = tf.train.AdamOptimizer(lr)\n",
    "    \n",
    "    image_batch, label_batch = image_label_queue()\n",
    "    \n",
    "    # Here's where we loop through our various GPUs\n",
    "    # G\n",
    "    grads = []\n",
    "    with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "        for i in range(NUM_GPU):\n",
    "            with tf.device('/gpu:{}'.format(i)):\n",
    "                with tf.name_scope('replica_{}'.format(i)):\n",
    "                    # Create model\n",
    "                    logits = vgg_model(image_batch)\n",
    "                    loss = vgg_loss(logits, label_batch)\n",
    "                    scope.reuse_variables()\n",
    "                    replica_grad = opt.compute_gradients(loss)\n",
    "                    grads.append(replica_grad)\n",
    "                    tf.summary.scalar('loss', loss)\n",
    "       \n",
    "    avg_grads = average_gradients(grads)            \n",
    "    train = opt.apply_gradients(avg_grads, global_step=global_step)\n",
    "    \n",
    "    for grad, var in avg_grads:\n",
    "        if grad is not None:\n",
    "            tf.summary.histogram(var.op.name + '_gradients', grad)\n",
    "    \n",
    "    for var in tf.trainable_variables():\n",
    "        tf.summary.histogram(var.op.name, var)\n",
    "    \n",
    "    summary_op = tf.summary.merge_all()\n",
    "        \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config=tf.ConfigProto(\n",
    "    allow_soft_placement=True,\n",
    "    log_device_placement=True\n",
    ")    \n",
    "\n",
    "writer = tf.summary.FileWriter('tbout/multigpu', graph=multi_graph)\n",
    "\n",
    "sess = tf.Session(config=config, graph=multi_graph)  \n",
    "sess.run(init)\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "try:\n",
    "    i = 0\n",
    "    while i < 10000 and not coord.should_stop():\n",
    "        if i % 100 == 0:\n",
    "            err, step, summ, _ = sess.run([loss, inc_step, summary_op, train])\n",
    "            writer.add_summary(summ, step)\n",
    "            writer.flush()\n",
    "        else:\n",
    "            err, step, _ = sess.run([loss, inc_step, train])\n",
    "\n",
    "        if step % 1000 == 0 or step == 1:\n",
    "            saver.save(sess, os.path.join(CKPT_PATH, 'vgg.ckpt'), step)\n",
    "        \n",
    "        i += 1\n",
    "        # Don't want to run a bunch of training steps in the notebook! Remove me in a real application\n",
    "        break\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('done!')\n",
    "finally:\n",
    "    coord.request_stop()\n",
    "    try:\n",
    "        coord.join(threads)\n",
    "    except RuntimeError as e:\n",
    "        print('Threads not done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RuntimeError"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Show and Tell\n",
    "\n",
    "![](images/12/showandtell.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## VOCABULARY SETTINGS\n",
    "# The number of words in our input vocabulary\n",
    "IN_VOCAB = 10000\n",
    "# The size of our embedded input word vectors\n",
    "IN_EMBED_SIZE = 100\n",
    "# The number of words in our output vocabulary\n",
    "OUT_VOCAB = 10000\n",
    "# The size of our embedded output word vectors\n",
    "OUT_EMBED_SIZE = 4096\n",
    "\n",
    "## RNN SETTINGS\n",
    "# The number of units/neurons in each layer of RNN cells. \n",
    "RNN_WIDTH = 1000\n",
    "# The layers of RNN cells for both the encoder and decoder\n",
    "RNN_DEPTH = 4\n",
    "# The maximum sequence length for our inputs\n",
    "MAX_LEN_INPUTS = 10\n",
    "# The maximum sequence length for our outputs\n",
    "MAX_LEN_LABELS = 10\n",
    "\n",
    "## TRAINING SETTINGS\n",
    "# The size of our training batch\n",
    "BATCH_SIZE = 32\n",
    "# The number of negative samples to sample for our sampled softmax loss\n",
    "NUM_SAMPLES=50\n",
    "\n",
    "show_graph = tf.Graph()\n",
    "with show_graph.as_default():\n",
    "    inputs = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    labels = tf.placeholder(tf.int32, [None, MAX_LEN_LABELS])\n",
    "    labels_length = tf.placeholder(tf.int32, [None])\n",
    "    \n",
    "    # Encoder\n",
    "    \n",
    "    vgg_logits = vgg_model(inputs)\n",
    "    encoded_image = show_graph.get_tensor_by_name('vgg_net/f18/Relu:0')\n",
    "    \n",
    "    # Decoder\n",
    "    output_embedding = tf.Variable(tf.truncated_normal([OUT_VOCAB, OUT_EMBED_SIZE]))\n",
    "    w = tf.Variable(tf.truncated_normal([RNN_WIDTH, OUT_VOCAB]))\n",
    "    b = tf.Variable(tf.zeros([OUT_VOCAB]))\n",
    "    \n",
    "    cell_base = tf.contrib.rnn.GRUCell\n",
    "    dec_cells = [cell_base(RNN_WIDTH) for _ in range(RNN_DEPTH)]\n",
    "    dec_cell = tf.contrib.rnn.MultiRNNCell(dec_cells)\n",
    "    \n",
    "    # Initial decoder state is zero, instead of encoder state (not an RNN encoder)\n",
    "    dec_state = tuple(tf.unstack(tf.zeros([RNN_DEPTH,tf.shape(labels)[0], RNN_WIDTH])))\n",
    "    # Initial input is the encoded image\n",
    "    output, dec_state = dec_cell(encoded_image, dec_state)\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    \n",
    "    # Don't append the output from the first LSTM\n",
    "    outputs = []\n",
    "    logits = []\n",
    "    prev = output\n",
    "    for i, label in enumerate(tf.unstack(labels, axis=1)):\n",
    "        logit = tf.matmul(prev, w) + b\n",
    "        logits.append(logit)\n",
    "        label_idx = tf.argmax(logit, 1)\n",
    "        label_emb = tf.nn.embedding_lookup(output_embedding, label_idx)\n",
    "        prev, dec_state = dec_cell(label_emb, dec_state)\n",
    "        if i > 0:\n",
    "            outputs.append(prev)\n",
    "\n",
    "    lengths_exp = tf.expand_dims(labels_length, 1)\n",
    "    mask = tf.reshape(tf.tile(tf.range(MAX_LEN_LABELS), [tf.shape(labels)[0]]), [-1, MAX_LEN_LABELS], name='mask_reshape')\n",
    "    mask = tf.to_float(tf.less(mask, lengths_exp))\n",
    "    \n",
    "    def s_loss(logits, labels):\n",
    "        logits = tf.reshape(logits, [-1, RNN_WIDTH], name='logit_s')\n",
    "        labels = tf.reshape(labels, [-1, 1], name='label_s')\n",
    "        return tf.nn.sampled_softmax_loss(\n",
    "            weights=tf.transpose(w),\n",
    "            biases=b,\n",
    "            labels=labels,\n",
    "            inputs=logits,\n",
    "            num_sampled=NUM_SAMPLES,\n",
    "            num_classes=OUT_VOCAB\n",
    "        )\n",
    "    test = tf.convert_to_tensor(outputs)\n",
    "    outputs_tensor = tf.reshape(tf.convert_to_tensor(outputs), [-1, MAX_LEN_LABELS, RNN_WIDTH], name='logit_reshape')\n",
    "    labels_float = tf.to_float(labels)\n",
    "    loss = tf.contrib.seq2seq.sequence_loss(outputs_tensor, labels_float, mask, softmax_loss_function=s_loss)\n",
    "    \n",
    "    learning_rate = tf.placeholder(tf.float32, [])\n",
    "    train = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    inc_step = tf.assign_add(global_step, 1, name='inc_step')\n",
    "    \n",
    "    logits_tensor = tf.reshape(tf.convert_to_tensor(logits), [-1, MAX_LEN_LABELS, OUT_VOCAB])\n",
    "    softmax = tf.nn.softmax(logits_tensor)\n",
    "    predictions = tf.to_int32(tf.argmax(softmax, 2))\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
